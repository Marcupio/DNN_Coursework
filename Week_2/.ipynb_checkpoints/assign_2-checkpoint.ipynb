{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can perform standard image augmentations within Keras ImageDataGenerator module. For this we use the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 20s 0us/step\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train),(x_test,y_test) = cifar10.load_data()\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We first set up an ImageDataGenerator which will perform the augmentations we have specified. In this case we perfrom random flipping in both directions, along with random rotations up to a specified range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(vertical_flip= True, #random vertical flipping of training images\n",
    "                            horizontal_flip = True, #random horizontal flipping of training images\n",
    "                            rotation_range= 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(layers.Flatten(input_shape = (32,32,3)))\n",
    "model.add(layers.Dense(64, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer ='adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We use keras' flow method to pass the image data through our ImageDataGenerator which will augment the data before feeding it to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 2.0973 - accuracy: 0.2055\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 1.9776 - accuracy: 0.1228\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 1.9344 - accuracy: 0.1121\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 1.8975 - accuracy: 0.1044\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 1.8630 - accuracy: 0.0971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a66480d940>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test = x_train/255.0, x_test/255.0\n",
    "model.fit(datagen.flow(x_train,y_train), epochs= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8057 - accuracy: 0.0891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8057101964950562, 0.08910000324249268]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The results are horrendous, but the point was to show the use of image augementation. Of course we could manipulate the data a bit , a good first step would be to perform one-hot encoding of the labels. Along with tuning the model/adding other layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
